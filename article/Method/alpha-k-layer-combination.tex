\subsection{Optimizing layer combination}
\subsubsection{Removing $\alpha_k$}
% Overvej om denne sektion b√∏r flyttes til appendix med en reference til den.
Before trying to optimize $\alpha_k$ we wanted to investigate what impact it had.
The simplest experiment is to change the value of $\alpha_k$ to 1 which essentially removes it.
If this results in small changes in performance, it could indicate that it would not be worthwhile to pursue the opportunity to optimize $\alpha_k$.
\begin{equation}
    \mathbf{e}_u = \sum_{k=0}^{K} \mathbf{e}_u^{(k)},
    \label{eq:lightgcn-sum}
\end{equation}
The result of the experiment can be seen in \autoref{subsubsec:remove-alpha-k}

\subsubsection{Optimizing $\alpha_k$}
% Definer matematikken
The initial idea of optimizing $\alpha_k$ was to change each layer's effect depending on how many connections each node had.
An example can be seen \autoref{tab:alpha-example}.
The numbers shown on the table are arbitrary and different variables need to be tested to see how well it performs.
The intuition behind this is that the effect of each layer in the GCN being dependent on the number of connections that the node has would be beneficial.
A node with only 1 connection will not benefit much from the first convolution but will be richer in information in the third convolution.
For a node with 200 connections, the third convolution might actually be harmful, as the node gets impacted too much by too many nodes, where 1 convolution is enough to make it perform optimally.

\begin{table}[]
    \centering
    \begin{tabular}{|l|l|}
        \hline
        Number of connections & Effect of each layer      \\ \hline
        0 - 20                & \begin{tabular}[c]{@{}l@{}}10 \% effect of $e^{(0)}$\\ 15 \% effect of $e^{(1)}$\\ 25 \% effect of $e^{(2)}$\\ 50 \% effect of $e^{(3)}$\end{tabular} \\ \hline
        21-50                 & \begin{tabular}[c]{@{}l@{}}10 \% effect of $e^{(0)}$\\ 10 \% effect of $e^{(1)}$\\ 60 \% effect of $e^{(2)}$\\ 20 \% effect of $e^{(3)}$\end{tabular} \\ \hline
        50+                   & \begin{tabular}[c]{@{}l@{}}10 \% effect of $e^{(0)}$ \\ 50 \% effect of $e^{(1)}$\\ 20 \% effect of $e^{(2)}$ \\ 20 \% effect of $e^{(3)}$\end{tabular} \\ \hline
    \end{tabular}
    \caption{Example of the changed effect to $\alpha_k$. }
    \label{tab:alpha-example}
\end{table}

\paragraph{Layer effect based on performance} \label{fredsplit}
Based on the results from the node degree experiments seen in \autoref{subsec:degree-experiment}, we decided to make an algorithm that calculated each layers' effect based on how they performed compared to each other.
It could clearly be seen that some layers performed substantially better than others and therefore the worst layers might have a negative effect on the final embedding.
\\
The algorithms looks at the performance of each individual layers and then based on how many percent's worse they perform compared to the best layer they will get a penalty in their effect and the other layers will get an increase.
Two algorithms have been created where one has a more aggressive approach, that can completely remove certain layers, and a more balanced approach, where each layer will be ensured influence.
An example of the aggressive algorithm can be seen on \autoref{fig:fredsplitAgg} and and the balanced algorithm on \autoref{fig:fredsplitBal}.
Given four layers on \autoref{fig:fredsplitAgg} each layer will have 25\% effect on the final embedding at the start.
The worst layer performs 15\% worse than the best layer, we therefore remove 15 from 25 to get its final effect of 10.
Meanwhile, the 15 is split evenly among the other 3 layers who now have an effect of 30\%.
The same process is then repeated but the worst performing layer from the previous iteration is excluded.
This continues until all layers have gotten an effect penalty except the best performing layer.
This can result in one or more layers having 0 \% effect in the end.
In the balanced version the worst-performing layer is not excluded from the previous iteration.
\\
On \autoref{alg:aggresive-layereffect} the pseudocode for the aggressive algorithm can be seen.
The algorithm is given a list of how much worse each layer performed in percentage compared to the best performing layer in the same list.
At the start each layers' effect \textit{effect} is set to be the same.
After this the list \textit{L} is iterated over and the last element gets popped.
Since L is ordered the last element is the worst performing one.
Based on the start effect and how bad the layer has performed its new lower effect is calculated as well as the other layers effect increased.
On \autoref{alg:bal-layereffect} the pseudocode for the balanced method can be seen.
On \autoref{fig:fredsplitAgg} and \autoref{fig:fredsplitBal} examples of the aggressive and balanced algorithm can be seen.
In these examples we have 4 layers from 0 to 3.
Each have a start effect of 25\%.
Their performance is color coded so it easier to follow when they are used to calculate the new effect.
The yellow squares mark which layer is getting a lower effect in the current iteration and green marks the specific layer's final effect.
Comparing these two algorithms it can be seen that there is a larger diversion in the aggressive algorithm than in the balanced algorithm.
\begin{algorithm}
    \caption{Algorithm for the aggressive layer combination based on performance}
    \SetAlgoLined
    \KwResult{A list of how much effect each layer has on the final embedding }
    L = Ordered list of performance of each layer \\
    effect  = List of current effect for each layer \\
    \While{i < L.length; i++}{
        effect [i] = 100 / L.length \\
    }
    \While{L.length > 1; i++}{
        worseP = L.pop()\\
        newEffect  = max(Inf[i] - worseP, 0)\\
        \While{k < L.length; k++}{
            effect[k] = effect[k] + ((effect[i] - newEffect ) / L.length)\\
        }
        effect[i] = newEffect \\
    }
    \Return{effect.orderBy(layerId)}
    \label{alg:aggresive-layereffect}
\end{algorithm}

\begin{algorithm}
    \caption{Algorithm for the balanced layer combination based on performance}
    \SetAlgoLined
    \KwResult{A list of how much effect each layer has on the final embedding }
    L = Ordered list of performance of each layer \\
    effect  = List of current effect for each layer \\
    \While{i < L.length; i++}{
        effect [i] = 100 / L.length \\
    }
    \While{i = 0; i < L.length; i++}{
        worseP = L.[i]\\
        newEffect  = max(effect[i] - worseP, 0)\\
        \While{k = 0; k < L.length; k++}{
            if(k != i){
                    effect[k] = effect[k] + ((effect[i] - newEffect ) / (L.length-1))\\
                }
        }
        effect[i] = newEffect \\
    }
    \Return{effect.orderBy(layerId)}
    \label{alg:bal-layereffect}
\end{algorithm}


\begin{figure}
    \includegraphics[width=0.5\textwidth]{figures/fredsplit/aggresiveAlgo.png}
    \centering
    \caption{Example of aggressive splitting of layer effect based on performance}
    \label{fig:fredsplitAgg}
\end{figure}
\begin{figure}
    \includegraphics[width=0.5\textwidth]{figures/fredsplit/balancedAlgo.png}
    \centering
    \caption{Example of balanced splitting of layer effect based on performance}
    \label{fig:fredsplitBal}
\end{figure}
